{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataxy=pd.read_csv(\"FinalDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping valance\n",
    "DataVal=Dataxy.iloc[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senDfa0</th>\n",
       "      <th>senDfa1</th>\n",
       "      <th>senDfa2</th>\n",
       "      <th>senDfa3</th>\n",
       "      <th>senDfa4</th>\n",
       "      <th>senDfa5</th>\n",
       "      <th>senDfa6</th>\n",
       "      <th>senDfa7</th>\n",
       "      <th>senDfa8</th>\n",
       "      <th>senDfa9</th>\n",
       "      <th>...</th>\n",
       "      <th>senHurst31</th>\n",
       "      <th>senHurst32</th>\n",
       "      <th>senHurst33</th>\n",
       "      <th>senHurst34</th>\n",
       "      <th>senHurst35</th>\n",
       "      <th>senHurst36</th>\n",
       "      <th>senHurst37</th>\n",
       "      <th>senHurst38</th>\n",
       "      <th>senHurst39</th>\n",
       "      <th>Valance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002133</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.001559</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>-0.006688</td>\n",
       "      <td>-0.007642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131089</td>\n",
       "      <td>1.110708</td>\n",
       "      <td>0.890081</td>\n",
       "      <td>0.939189</td>\n",
       "      <td>1.033011</td>\n",
       "      <td>0.996901</td>\n",
       "      <td>0.809074</td>\n",
       "      <td>0.970004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006262</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.005583</td>\n",
       "      <td>-0.005103</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.003813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152521</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>1.098002</td>\n",
       "      <td>1.046685</td>\n",
       "      <td>1.085901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936995</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007681</td>\n",
       "      <td>-0.011060</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>-0.008348</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.008340</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>-0.008242</td>\n",
       "      <td>-0.010575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159770</td>\n",
       "      <td>1.063228</td>\n",
       "      <td>1.082313</td>\n",
       "      <td>1.063166</td>\n",
       "      <td>1.088769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543609</td>\n",
       "      <td>0.995391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.012013</td>\n",
       "      <td>-0.012038</td>\n",
       "      <td>-0.021174</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>-0.013477</td>\n",
       "      <td>-0.007505</td>\n",
       "      <td>-0.014245</td>\n",
       "      <td>-0.013097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168248</td>\n",
       "      <td>1.022074</td>\n",
       "      <td>1.117156</td>\n",
       "      <td>1.086076</td>\n",
       "      <td>1.157497</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>1.031969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009453</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>-0.008890</td>\n",
       "      <td>-0.005594</td>\n",
       "      <td>-0.008346</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>-0.004362</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>-0.008143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198912</td>\n",
       "      <td>0.996385</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>1.003874</td>\n",
       "      <td>1.174798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>1.086271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    senDfa0   senDfa1   senDfa2   senDfa3   senDfa4   senDfa5   senDfa6  \\\n",
       "0 -0.002133 -0.000325 -0.000156  0.001114  0.000636 -0.001559  0.001631   \n",
       "1 -0.006262 -0.006898 -0.009834 -0.008837 -0.005583 -0.005103 -0.005215   \n",
       "2 -0.007681 -0.011060 -0.008450 -0.003313 -0.008348 -0.004510 -0.008340   \n",
       "3 -0.017675 -0.012013 -0.012038 -0.021174 -0.018692 -0.003882 -0.013477   \n",
       "4 -0.009453 -0.006495 -0.006437 -0.008890 -0.005594 -0.008346 -0.004880   \n",
       "\n",
       "    senDfa7   senDfa8   senDfa9   ...     senHurst31  senHurst32  senHurst33  \\\n",
       "0  0.001380 -0.006688 -0.007642   ...       0.131089    1.110708    0.890081   \n",
       "1 -0.007236 -0.009539 -0.003813   ...       0.152521    0.849700    1.098002   \n",
       "2 -0.003636 -0.008242 -0.010575   ...       0.159770    1.063228    1.082313   \n",
       "3 -0.007505 -0.014245 -0.013097   ...       0.168248    1.022074    1.117156   \n",
       "4 -0.004362 -0.003013 -0.008143   ...       0.198912    0.996385    0.999356   \n",
       "\n",
       "   senHurst34  senHurst35  senHurst36  senHurst37  senHurst38  senHurst39  \\\n",
       "0    0.939189    1.033011    0.996901    0.809074    0.970004         NaN   \n",
       "1    1.046685    1.085901         NaN    0.936995    0.937595         NaN   \n",
       "2    1.063166    1.088769         NaN    0.543609    0.995391         NaN   \n",
       "3    1.086076    1.157497    0.978142    0.735437    1.031969         NaN   \n",
       "4    1.003874    1.174798         NaN    0.831288    1.086271         NaN   \n",
       "\n",
       "   Valance  \n",
       "0     7.71  \n",
       "1     8.10  \n",
       "2     8.58  \n",
       "3     4.94  \n",
       "4     6.96  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataVal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7.71\n",
       "1    8.10\n",
       "2    8.58\n",
       "3    4.94\n",
       "4    6.96\n",
       "Name: Valance, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=DataVal['Valance']\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7.71\n",
      "1    8.10\n",
      "2    8.58\n",
      "3    4.94\n",
      "4    6.96\n",
      "Name: Valance, dtype: float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    0.0\n",
      "4    1.0\n",
      "Name: Valance, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "##making the the valance binary \n",
    "bL= DataVal[\"Valance\"]\n",
    "print(bL.head())\n",
    "for idx in bL.index:\n",
    "    q = bL.get_value(idx, 'Valance')\n",
    "    if q>=5:\n",
    "        bL.set_value(idx,  1)\n",
    "    else :\n",
    "        bL.set_value(idx,  0)\n",
    "print(bL.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senDfa0</th>\n",
       "      <th>senDfa1</th>\n",
       "      <th>senDfa2</th>\n",
       "      <th>senDfa3</th>\n",
       "      <th>senDfa4</th>\n",
       "      <th>senDfa5</th>\n",
       "      <th>senDfa6</th>\n",
       "      <th>senDfa7</th>\n",
       "      <th>senDfa8</th>\n",
       "      <th>senDfa9</th>\n",
       "      <th>...</th>\n",
       "      <th>senHurst31</th>\n",
       "      <th>senHurst32</th>\n",
       "      <th>senHurst33</th>\n",
       "      <th>senHurst34</th>\n",
       "      <th>senHurst35</th>\n",
       "      <th>senHurst36</th>\n",
       "      <th>senHurst37</th>\n",
       "      <th>senHurst38</th>\n",
       "      <th>senHurst39</th>\n",
       "      <th>Valance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002133</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.001559</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>-0.006688</td>\n",
       "      <td>-0.007642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131089</td>\n",
       "      <td>1.110708</td>\n",
       "      <td>0.890081</td>\n",
       "      <td>0.939189</td>\n",
       "      <td>1.033011</td>\n",
       "      <td>0.996901</td>\n",
       "      <td>0.809074</td>\n",
       "      <td>0.970004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006262</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.005583</td>\n",
       "      <td>-0.005103</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.003813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152521</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>1.098002</td>\n",
       "      <td>1.046685</td>\n",
       "      <td>1.085901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.936995</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007681</td>\n",
       "      <td>-0.011060</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>-0.008348</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.008340</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>-0.008242</td>\n",
       "      <td>-0.010575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159770</td>\n",
       "      <td>1.063228</td>\n",
       "      <td>1.082313</td>\n",
       "      <td>1.063166</td>\n",
       "      <td>1.088769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543609</td>\n",
       "      <td>0.995391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.012013</td>\n",
       "      <td>-0.012038</td>\n",
       "      <td>-0.021174</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>-0.013477</td>\n",
       "      <td>-0.007505</td>\n",
       "      <td>-0.014245</td>\n",
       "      <td>-0.013097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168248</td>\n",
       "      <td>1.022074</td>\n",
       "      <td>1.117156</td>\n",
       "      <td>1.086076</td>\n",
       "      <td>1.157497</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>1.031969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009453</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>-0.008890</td>\n",
       "      <td>-0.005594</td>\n",
       "      <td>-0.008346</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>-0.004362</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>-0.008143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198912</td>\n",
       "      <td>0.996385</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>1.003874</td>\n",
       "      <td>1.174798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>1.086271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    senDfa0   senDfa1   senDfa2   senDfa3   senDfa4   senDfa5   senDfa6  \\\n",
       "0 -0.002133 -0.000325 -0.000156  0.001114  0.000636 -0.001559  0.001631   \n",
       "1 -0.006262 -0.006898 -0.009834 -0.008837 -0.005583 -0.005103 -0.005215   \n",
       "2 -0.007681 -0.011060 -0.008450 -0.003313 -0.008348 -0.004510 -0.008340   \n",
       "3 -0.017675 -0.012013 -0.012038 -0.021174 -0.018692 -0.003882 -0.013477   \n",
       "4 -0.009453 -0.006495 -0.006437 -0.008890 -0.005594 -0.008346 -0.004880   \n",
       "\n",
       "    senDfa7   senDfa8   senDfa9   ...     senHurst31  senHurst32  senHurst33  \\\n",
       "0  0.001380 -0.006688 -0.007642   ...       0.131089    1.110708    0.890081   \n",
       "1 -0.007236 -0.009539 -0.003813   ...       0.152521    0.849700    1.098002   \n",
       "2 -0.003636 -0.008242 -0.010575   ...       0.159770    1.063228    1.082313   \n",
       "3 -0.007505 -0.014245 -0.013097   ...       0.168248    1.022074    1.117156   \n",
       "4 -0.004362 -0.003013 -0.008143   ...       0.198912    0.996385    0.999356   \n",
       "\n",
       "   senHurst34  senHurst35  senHurst36  senHurst37  senHurst38  senHurst39  \\\n",
       "0    0.939189    1.033011    0.996901    0.809074    0.970004         NaN   \n",
       "1    1.046685    1.085901         NaN    0.936995    0.937595         NaN   \n",
       "2    1.063166    1.088769         NaN    0.543609    0.995391         NaN   \n",
       "3    1.086076    1.157497    0.978142    0.735437    1.031969         NaN   \n",
       "4    1.003874    1.174798         NaN    0.831288    1.086271         NaN   \n",
       "\n",
       "   Valance  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      0.0  \n",
       "4      1.0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataVal['Valance'] = bL\n",
    "#DataVal=DataVal.drop('Valance', axis=1)\n",
    "#xd=pd.DataFrame(bL)\n",
    "#print(DataVal.head())\n",
    "DataVal.head()\n",
    "#DataVal.append(xd)\n",
    "#print(DataVal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataAr=DataAr.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  1.0\n",
       "2  1.0\n",
       "3  0.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = DataVal.iloc[:,:-1].values\n",
    "\n",
    "y = DataVal.iloc[:,-1].values\n",
    "y1=pd.DataFrame(y)\n",
    "y1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking care of missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN',strategy = 'median',axis=0)\n",
    "imputer = imputer.fit(X[:,:]) #SELECTING THE COLUMN WITH MISSING VALUES\n",
    "X[:,:] = imputer.transform(X[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002133</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.001559</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>-0.006688</td>\n",
       "      <td>-0.007642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183381</td>\n",
       "      <td>0.131089</td>\n",
       "      <td>1.110708</td>\n",
       "      <td>0.890081</td>\n",
       "      <td>0.939189</td>\n",
       "      <td>1.033011</td>\n",
       "      <td>0.996901</td>\n",
       "      <td>0.809074</td>\n",
       "      <td>0.970004</td>\n",
       "      <td>1.060949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006262</td>\n",
       "      <td>-0.006898</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.005583</td>\n",
       "      <td>-0.005103</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>-0.007236</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>-0.003813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254699</td>\n",
       "      <td>0.152521</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>1.098002</td>\n",
       "      <td>1.046685</td>\n",
       "      <td>1.085901</td>\n",
       "      <td>1.001500</td>\n",
       "      <td>0.936995</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>1.060949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007681</td>\n",
       "      <td>-0.011060</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>-0.008348</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.008340</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>-0.008242</td>\n",
       "      <td>-0.010575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245180</td>\n",
       "      <td>0.159770</td>\n",
       "      <td>1.063228</td>\n",
       "      <td>1.082313</td>\n",
       "      <td>1.063166</td>\n",
       "      <td>1.088769</td>\n",
       "      <td>1.001500</td>\n",
       "      <td>0.543609</td>\n",
       "      <td>0.995391</td>\n",
       "      <td>1.060949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.012013</td>\n",
       "      <td>-0.012038</td>\n",
       "      <td>-0.021174</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>-0.013477</td>\n",
       "      <td>-0.007505</td>\n",
       "      <td>-0.014245</td>\n",
       "      <td>-0.013097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209498</td>\n",
       "      <td>0.168248</td>\n",
       "      <td>1.022074</td>\n",
       "      <td>1.117156</td>\n",
       "      <td>1.086076</td>\n",
       "      <td>1.157497</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>1.031969</td>\n",
       "      <td>1.060949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009453</td>\n",
       "      <td>-0.006495</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>-0.008890</td>\n",
       "      <td>-0.005594</td>\n",
       "      <td>-0.008346</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>-0.004362</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>-0.008143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168669</td>\n",
       "      <td>0.198912</td>\n",
       "      <td>0.996385</td>\n",
       "      <td>0.999356</td>\n",
       "      <td>1.003874</td>\n",
       "      <td>1.174798</td>\n",
       "      <td>1.001500</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>1.086271</td>\n",
       "      <td>1.060949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.002133 -0.000325 -0.000156  0.001114  0.000636 -0.001559  0.001631   \n",
       "1 -0.006262 -0.006898 -0.009834 -0.008837 -0.005583 -0.005103 -0.005215   \n",
       "2 -0.007681 -0.011060 -0.008450 -0.003313 -0.008348 -0.004510 -0.008340   \n",
       "3 -0.017675 -0.012013 -0.012038 -0.021174 -0.018692 -0.003882 -0.013477   \n",
       "4 -0.009453 -0.006495 -0.006437 -0.008890 -0.005594 -0.008346 -0.004880   \n",
       "\n",
       "        7         8         9      ...          110       111       112  \\\n",
       "0  0.001380 -0.006688 -0.007642    ...     0.183381  0.131089  1.110708   \n",
       "1 -0.007236 -0.009539 -0.003813    ...     0.254699  0.152521  0.849700   \n",
       "2 -0.003636 -0.008242 -0.010575    ...     0.245180  0.159770  1.063228   \n",
       "3 -0.007505 -0.014245 -0.013097    ...     0.209498  0.168248  1.022074   \n",
       "4 -0.004362 -0.003013 -0.008143    ...     0.168669  0.198912  0.996385   \n",
       "\n",
       "        113       114       115       116       117       118       119  \n",
       "0  0.890081  0.939189  1.033011  0.996901  0.809074  0.970004  1.060949  \n",
       "1  1.098002  1.046685  1.085901  1.001500  0.936995  0.937595  1.060949  \n",
       "2  1.082313  1.063166  1.088769  1.001500  0.543609  0.995391  1.060949  \n",
       "3  1.117156  1.086076  1.157497  0.978142  0.735437  1.031969  1.060949  \n",
       "4  0.999356  1.003874  1.174798  1.001500  0.831288  1.086271  1.060949  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1=pd.DataFrame(X)\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataVal.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 130)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "#sc_y = StandardScaler()\n",
    "#y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse for linear regression:  0.5297040164863488\n",
      "MAE for linear regression:  0.47736915159059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "print(\"rmse for linear regression: \",rmse)\n",
    "print(\"MAE for linear regression: \",mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
      " 0 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 1 0 1\n",
      " 1 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1\n",
      " 1 1 1 0 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0]\n",
      "[1 1 1 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_train=y_train.astype(int)\n",
    "y_test=y_test.astype(int)\n",
    "print(y_test)\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60546875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "regress = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 5, \n",
    "                                    min_samples_split= 5, n_estimators= 40, subsample= 0.9)\n",
    "\n",
    "regress.fit(X_train, y_train)\n",
    "y_pred1 = regress.predict(X_test)\n",
    "\n",
    "o = accuracy_score(y_test, y_pred1)\n",
    "print(o)\n",
    "#rmse1 = np.sqrt(mean_squared_error(y_test,y_pred1))\n",
    "#mae1=mean_absolute_error(y_test,y_pred)\n",
    "#print(\"rmse for XGBRegressor: \",rmse1)\n",
    "#print(\"MAE for XGBRegressor: \",mae1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 384 candidates, totalling 1536 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-e8bcba20c475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m grid_mse = GridSearchCV(estimator=regress, param_grid=gbm_param_grid1,\n\u001b[0;32m     11\u001b[0m                         scoring='neg_mean_squared_error', cv=4, verbose=1)\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgrid_mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid_mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1034\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 788\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################warning#######################################################\n",
    "\n",
    "\n",
    "\n",
    "#########################large Computation##############################################\n",
    "\n",
    "\n",
    "\n",
    "##GridSearch for GB_Regressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gbm_param_grid1 = {\n",
    "   'learning_rate':[0.1,0.2],\n",
    "    'n_estimators':[50,40,60,70], \n",
    "    'max_depth': [5,6,4],\n",
    "    'min_samples_split': [4,5,6,7],\n",
    "    'subsample':[0.7,0.6,0.8,0.9]\n",
    "}\n",
    "grid_mse = GridSearchCV(estimator=regress, param_grid=gbm_param_grid1,\n",
    "                        scoring='neg_mean_squared_error', cv=4, verbose=1)\n",
    "grid_mse.fit(X_train, y_train)\n",
    "print(\"Best parameters: \",grid_mse.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "regressor1 = xgb.XGBClassifier(colsample_bylevel= 0.2, colsample_bytree= 0.3,\n",
    "                             learning_rate= 0.1, max_depth= 2, \n",
    "                             min_child_weight= 3, n_estimators= 50)\n",
    "regressor1.fit(X_train, y_train)\n",
    "y_pred = regressor1.predict(X_test)\n",
    "rmse2= np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "mae2=mean_absolute_error(y_test,y_pred)\n",
    "o = accuracy_score(y_test, y_pred)\n",
    "print(o)\n",
    "print(\"rmse for xgboost: \",rmse2)\n",
    "print(\"MAE for xgboost: \",mae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 486 candidates, totalling 1944 fits\n",
      "Best parameters:  {'colsample_bylevel': 0.2, 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 2, 'min_child_weight': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1944 out of 1944 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "#########################warning#######################################################\n",
    "\n",
    "\n",
    "\n",
    "#########################large Computation##############################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "regressor1 = xgb.XGBRegressor()\n",
    "abalone_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50,100,200],\n",
    "    'max_depth': [2,3,4],\n",
    "    'learning_rate': [0.1,0.2,0.3],\n",
    "    'colsample_bylevel': [0.2,0.7,1],\n",
    "    'min_child_weight': [1,2,3]\n",
    "}\n",
    "grid_mse = GridSearchCV(estimator=regressor1, param_grid=gbm_param_grid,\n",
    "                        scoring='neg_mean_squared_error', cv=4, verbose=1)\n",
    "grid_mse.fit(X_train, y_train)\n",
    "print(\"Best parameters: \",grid_mse.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  real\n",
       "0    1     0\n",
       "1    1     1\n",
       "2    0     1\n",
       "3    1     1\n",
       "4    1     1\n",
       "5    0     1\n",
       "6    1     0\n",
       "7    1     0\n",
       "8    1     1\n",
       "9    1     1\n",
       "10   0     0\n",
       "11   1     0\n",
       "12   1     0\n",
       "13   1     1\n",
       "14   1     0\n",
       "15   1     0\n",
       "16   1     0\n",
       "17   1     1\n",
       "18   1     0\n",
       "19   1     1\n",
       "20   1     1\n",
       "21   1     1\n",
       "22   1     1\n",
       "23   1     1\n",
       "24   1     1\n",
       "25   1     1\n",
       "26   1     0\n",
       "27   1     1\n",
       "28   1     1\n",
       "29   1     1\n",
       "..  ..   ...\n",
       "226  1     1\n",
       "227  0     0\n",
       "228  0     0\n",
       "229  1     1\n",
       "230  1     0\n",
       "231  0     0\n",
       "232  1     1\n",
       "233  1     0\n",
       "234  1     1\n",
       "235  1     1\n",
       "236  1     1\n",
       "237  0     1\n",
       "238  0     1\n",
       "239  1     1\n",
       "240  1     1\n",
       "241  0     0\n",
       "242  1     1\n",
       "243  1     0\n",
       "244  1     0\n",
       "245  1     1\n",
       "246  1     1\n",
       "247  1     1\n",
       "248  1     1\n",
       "249  1     1\n",
       "250  1     1\n",
       "251  1     1\n",
       "252  1     0\n",
       "253  0     0\n",
       "254  1     0\n",
       "255  0     0\n",
       "\n",
       "[256 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.DataFrame(y_pred)\n",
    "data2 = pd.DataFrame(y_test)\n",
    "#data1.join(data2)\n",
    "label=[\"real\"]\n",
    "data2.columns=label\n",
    "data1.join(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1024/1024 [==============================] - 0s 355us/step - loss: 0.7176 - acc: 0.5371\n",
      "Epoch 2/25\n",
      "1024/1024 [==============================] - 0s 45us/step - loss: 0.6447 - acc: 0.6260\n",
      "Epoch 3/25\n",
      "1024/1024 [==============================] - 0s 54us/step - loss: 0.6128 - acc: 0.6670\n",
      "Epoch 4/25\n",
      "1024/1024 [==============================] - 0s 48us/step - loss: 0.5891 - acc: 0.7100\n",
      "Epoch 5/25\n",
      "1024/1024 [==============================] - 0s 51us/step - loss: 0.5648 - acc: 0.7275\n",
      "Epoch 6/25\n",
      "1024/1024 [==============================] - 0s 55us/step - loss: 0.5390 - acc: 0.7490\n",
      "Epoch 7/25\n",
      "1024/1024 [==============================] - 0s 53us/step - loss: 0.5151 - acc: 0.7725\n",
      "Epoch 8/25\n",
      "1024/1024 [==============================] - 0s 47us/step - loss: 0.5007 - acc: 0.7705\n",
      "Epoch 9/25\n",
      "1024/1024 [==============================] - 0s 49us/step - loss: 0.4783 - acc: 0.8018\n",
      "Epoch 10/25\n",
      "1024/1024 [==============================] - 0s 51us/step - loss: 0.4564 - acc: 0.8193\n",
      "Epoch 11/25\n",
      "1024/1024 [==============================] - 0s 50us/step - loss: 0.4350 - acc: 0.8281\n",
      "Epoch 12/25\n",
      "1024/1024 [==============================] - 0s 48us/step - loss: 0.4130 - acc: 0.8418\n",
      "Epoch 13/25\n",
      "1024/1024 [==============================] - 0s 55us/step - loss: 0.3964 - acc: 0.8477\n",
      "Epoch 14/25\n",
      "1024/1024 [==============================] - 0s 51us/step - loss: 0.3732 - acc: 0.8711\n",
      "Epoch 15/25\n",
      "1024/1024 [==============================] - 0s 51us/step - loss: 0.3562 - acc: 0.8760\n",
      "Epoch 16/25\n",
      "1024/1024 [==============================] - 0s 49us/step - loss: 0.3388 - acc: 0.8984\n",
      "Epoch 17/25\n",
      "1024/1024 [==============================] - 0s 53us/step - loss: 0.3157 - acc: 0.9131\n",
      "Epoch 18/25\n",
      "1024/1024 [==============================] - 0s 51us/step - loss: 0.2973 - acc: 0.9297\n",
      "Epoch 19/25\n",
      "1024/1024 [==============================] - 0s 50us/step - loss: 0.2830 - acc: 0.9219\n",
      "Epoch 20/25\n",
      "1024/1024 [==============================] - 0s 50us/step - loss: 0.2619 - acc: 0.9453\n",
      "Epoch 21/25\n",
      "1024/1024 [==============================] - 0s 41us/step - loss: 0.2428 - acc: 0.9492\n",
      "Epoch 22/25\n",
      "1024/1024 [==============================] - 0s 57us/step - loss: 0.2290 - acc: 0.9502\n",
      "Epoch 23/25\n",
      "1024/1024 [==============================] - 0s 68us/step - loss: 0.2117 - acc: 0.9492\n",
      "Epoch 24/25\n",
      "1024/1024 [==============================] - 0s 51us/step - loss: 0.2102 - acc: 0.9541\n",
      "Epoch 25/25\n",
      "1024/1024 [==============================] - 0s 63us/step - loss: 0.1839 - acc: 0.9668\n",
      "[[9.55509603e-01]\n",
      " [8.53993237e-01]\n",
      " [5.86075336e-02]\n",
      " [2.92490751e-01]\n",
      " [9.17627990e-01]\n",
      " [9.14756894e-01]\n",
      " [2.78771758e-01]\n",
      " [4.19936836e-01]\n",
      " [8.75969768e-01]\n",
      " [6.09848201e-01]\n",
      " [9.95897967e-03]\n",
      " [6.15254283e-01]\n",
      " [9.48436618e-01]\n",
      " [9.91709292e-01]\n",
      " [7.28648543e-01]\n",
      " [7.60441959e-01]\n",
      " [5.83869278e-01]\n",
      " [4.19274151e-01]\n",
      " [9.18866515e-01]\n",
      " [7.75040388e-01]\n",
      " [8.81689191e-01]\n",
      " [9.52804506e-01]\n",
      " [2.99645007e-01]\n",
      " [6.80284262e-01]\n",
      " [9.62917924e-01]\n",
      " [5.72289266e-02]\n",
      " [1.36532933e-01]\n",
      " [9.58432972e-01]\n",
      " [6.47413507e-02]\n",
      " [8.23649943e-01]\n",
      " [1.82175532e-01]\n",
      " [7.39925504e-01]\n",
      " [9.33440745e-01]\n",
      " [6.79992497e-01]\n",
      " [9.71701562e-01]\n",
      " [2.76571605e-02]\n",
      " [8.54496583e-02]\n",
      " [6.97555244e-01]\n",
      " [3.18572909e-01]\n",
      " [7.51173198e-01]\n",
      " [9.91187036e-01]\n",
      " [7.68251240e-01]\n",
      " [2.24239826e-02]\n",
      " [1.34948999e-01]\n",
      " [5.13692021e-01]\n",
      " [9.45065379e-01]\n",
      " [9.95537281e-01]\n",
      " [5.47153533e-01]\n",
      " [9.55298305e-01]\n",
      " [2.62199461e-01]\n",
      " [1.24792710e-01]\n",
      " [9.43612635e-01]\n",
      " [7.81830251e-01]\n",
      " [8.56237173e-01]\n",
      " [8.28212738e-01]\n",
      " [7.97903478e-01]\n",
      " [8.81953299e-01]\n",
      " [8.27856123e-01]\n",
      " [5.03468037e-01]\n",
      " [2.74181992e-01]\n",
      " [2.56843239e-01]\n",
      " [9.69840109e-01]\n",
      " [4.20348287e-01]\n",
      " [9.83262539e-01]\n",
      " [7.29279757e-01]\n",
      " [9.79584932e-01]\n",
      " [3.75828184e-02]\n",
      " [4.72279370e-01]\n",
      " [9.78921354e-02]\n",
      " [3.52275848e-01]\n",
      " [1.29105598e-01]\n",
      " [8.84135604e-01]\n",
      " [1.90004185e-01]\n",
      " [8.68344545e-01]\n",
      " [8.98518682e-01]\n",
      " [5.08991443e-02]\n",
      " [8.94999862e-01]\n",
      " [4.59031697e-04]\n",
      " [3.61659229e-01]\n",
      " [8.59674573e-01]\n",
      " [8.17417622e-01]\n",
      " [9.82475281e-01]\n",
      " [4.68361855e-01]\n",
      " [9.32849288e-01]\n",
      " [2.25821123e-01]\n",
      " [3.74765098e-01]\n",
      " [1.27860963e-01]\n",
      " [5.50482087e-02]\n",
      " [9.36275780e-01]\n",
      " [9.56031561e-01]\n",
      " [4.98352140e-01]\n",
      " [9.28557277e-01]\n",
      " [2.52211064e-01]\n",
      " [5.47465086e-01]\n",
      " [2.35569209e-01]\n",
      " [9.95598257e-01]\n",
      " [9.10775542e-01]\n",
      " [3.62896860e-01]\n",
      " [1.81662682e-02]\n",
      " [4.85023737e-01]\n",
      " [9.00401950e-01]\n",
      " [3.41489017e-01]\n",
      " [1.77480057e-01]\n",
      " [1.23323537e-02]\n",
      " [9.33272600e-01]\n",
      " [1.00171939e-01]\n",
      " [2.34287873e-01]\n",
      " [6.50773108e-01]\n",
      " [2.74464185e-03]\n",
      " [7.74219215e-01]\n",
      " [1.64900701e-02]\n",
      " [1.61853224e-01]\n",
      " [8.76921654e-01]\n",
      " [3.22541237e-01]\n",
      " [9.99078274e-01]\n",
      " [3.45060825e-01]\n",
      " [2.04307988e-01]\n",
      " [9.00210023e-01]\n",
      " [4.41402614e-01]\n",
      " [8.98264349e-01]\n",
      " [8.08844447e-01]\n",
      " [8.21968257e-01]\n",
      " [8.90202641e-01]\n",
      " [1.71952732e-02]\n",
      " [5.11515200e-01]\n",
      " [9.95359957e-01]\n",
      " [8.14338863e-01]\n",
      " [2.94166952e-01]\n",
      " [8.29924941e-01]\n",
      " [2.77371913e-01]\n",
      " [1.20350048e-01]\n",
      " [4.59142745e-01]\n",
      " [7.80579925e-01]\n",
      " [1.94524884e-01]\n",
      " [5.93081057e-01]\n",
      " [7.87331879e-01]\n",
      " [3.89023758e-02]\n",
      " [5.06841421e-01]\n",
      " [5.00536382e-01]\n",
      " [1.67193666e-01]\n",
      " [3.97724569e-01]\n",
      " [3.90192866e-01]\n",
      " [9.59822178e-01]\n",
      " [1.13983236e-01]\n",
      " [7.63600826e-01]\n",
      " [9.91451681e-01]\n",
      " [8.17999095e-02]\n",
      " [3.21746469e-01]\n",
      " [6.10824525e-01]\n",
      " [5.45519516e-02]\n",
      " [9.26819682e-01]\n",
      " [5.72593629e-01]\n",
      " [4.47793752e-01]\n",
      " [4.60327446e-01]\n",
      " [4.64712650e-01]\n",
      " [5.74959397e-01]\n",
      " [2.33605400e-01]\n",
      " [6.41571358e-03]\n",
      " [6.57249093e-01]\n",
      " [3.44672948e-02]\n",
      " [9.30818081e-01]\n",
      " [9.45746303e-01]\n",
      " [9.51902449e-01]\n",
      " [6.23289406e-01]\n",
      " [5.87288678e-01]\n",
      " [9.39021766e-01]\n",
      " [9.38821018e-01]\n",
      " [6.47157669e-01]\n",
      " [8.09150577e-01]\n",
      " [2.82512218e-01]\n",
      " [8.18005562e-01]\n",
      " [2.23577097e-01]\n",
      " [2.52811342e-01]\n",
      " [7.50926137e-01]\n",
      " [9.59180057e-01]\n",
      " [1.92531347e-01]\n",
      " [7.89346337e-01]\n",
      " [9.43229198e-01]\n",
      " [9.92138207e-01]\n",
      " [6.18882835e-01]\n",
      " [9.94817793e-01]\n",
      " [1.02970064e-01]\n",
      " [9.44349468e-01]\n",
      " [3.74638200e-01]\n",
      " [8.39785993e-01]\n",
      " [6.71152413e-01]\n",
      " [8.42723072e-01]\n",
      " [4.62566286e-01]\n",
      " [1.19254276e-01]\n",
      " [7.62980640e-01]\n",
      " [3.71458888e-01]\n",
      " [9.31426346e-01]\n",
      " [9.74222600e-01]\n",
      " [8.69692326e-01]\n",
      " [1.84762981e-02]\n",
      " [8.75951767e-01]\n",
      " [9.95102882e-01]\n",
      " [9.71170127e-01]\n",
      " [7.13017762e-01]\n",
      " [1.17435582e-01]\n",
      " [5.62402666e-01]\n",
      " [6.75449014e-01]\n",
      " [2.94112833e-03]\n",
      " [5.98707378e-01]\n",
      " [6.15680404e-02]\n",
      " [5.88243082e-02]\n",
      " [5.28865218e-01]\n",
      " [5.78646958e-01]\n",
      " [1.61061008e-02]\n",
      " [9.90961969e-01]\n",
      " [4.24081892e-01]\n",
      " [9.85014975e-01]\n",
      " [9.24817204e-01]\n",
      " [7.33041942e-01]\n",
      " [7.97959447e-01]\n",
      " [3.77238193e-03]\n",
      " [7.64670908e-01]\n",
      " [5.70109725e-01]\n",
      " [5.92646040e-02]\n",
      " [8.12662721e-01]\n",
      " [2.79284060e-01]\n",
      " [9.49925005e-01]\n",
      " [2.16178685e-01]\n",
      " [7.49809921e-01]\n",
      " [9.56557333e-01]\n",
      " [9.40489769e-02]\n",
      " [9.41195786e-01]\n",
      " [1.41220182e-01]\n",
      " [6.05110049e-01]\n",
      " [5.27594805e-01]\n",
      " [9.89707470e-01]\n",
      " [1.13347314e-01]\n",
      " [4.83027548e-01]\n",
      " [6.65960848e-01]\n",
      " [4.00408655e-01]\n",
      " [2.47672811e-01]\n",
      " [6.57303482e-02]\n",
      " [8.41750577e-03]\n",
      " [9.52390313e-01]\n",
      " [3.04210573e-01]\n",
      " [3.92889120e-02]\n",
      " [2.48891816e-01]\n",
      " [3.64979535e-01]\n",
      " [4.26179558e-01]\n",
      " [5.61567366e-01]\n",
      " [6.67277992e-01]\n",
      " [9.40728009e-01]\n",
      " [9.69832301e-01]\n",
      " [6.93695664e-01]\n",
      " [8.04319799e-01]\n",
      " [9.60121095e-01]\n",
      " [6.80172801e-01]\n",
      " [2.62060642e-01]\n",
      " [1.46965057e-01]\n",
      " [5.99308133e-01]\n",
      " [1.85966212e-02]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-93e800e696e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my_pred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation\n",
    "\n",
    "# Create the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(100, input_dim=120, activation='relu'))\n",
    "model_1.add(Dense(20, activation='relu'))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_1.fit(X_train, y_train, epochs=25)\n",
    "\n",
    "y_pred1 = model_1.predict(X_test)\n",
    "print(y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mama\n",
      "0   1.0\n",
      "1   1.0\n",
      "2   0.0\n",
      "3   0.0\n",
      "4   1.0\n",
      "   mama\n",
      "0   1.0\n",
      "1   1.0\n",
      "2   0.0\n",
      "3   0.0\n",
      "4   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "##making the the valance binary \n",
    "gg=pd.DataFrame(y_pred1)\n",
    "gg.columns=[\"mama\"]\n",
    "print(gg.head())\n",
    "for idx in gg.index:\n",
    "    q = gg.get_value(idx, 'mama')\n",
    "    #print(q)\n",
    "    if q>=0.5:\n",
    "        gg.set_value(idx,'mama',1)\n",
    "    else :\n",
    "        gg.set_value(idx,'mama',0)\n",
    "print(gg.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=gg.values\n",
    "\n",
    "y_pred=y_pred.astype(int)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5390625\n"
     ]
    }
   ],
   "source": [
    "o = accuracy_score(y_test, y_pred)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
